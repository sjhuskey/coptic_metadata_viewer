{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a7d6ede",
   "metadata": {},
   "source": [
    "# Test for GraphSparqlQAChain\n",
    "\n",
    "Following tutorial at <https://python.langchain.com/docs/integrations/graphs/rdflib_sparql/>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e6bb093",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import GraphSparqlQAChain\n",
    "from langchain_community.graphs import RdfGraph\n",
    "from langchain_core.runnables import Runnable, RunnableSequence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd7e3eb",
   "metadata": {},
   "source": [
    "## Initialize the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0780ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the RDF graph\n",
    "graph = RdfGraph(\n",
    "    standard=\"rdf\",\n",
    "    serialization=\"ttl\",\n",
    "    source_file=\"/Users/sjhuskey/Python/coptic_metadata_viewer/streamlit_app/graph/graph.ttl\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6ca4682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the schema from the graph\n",
    "schema = graph.load_schema()\n",
    "schema = graph.get_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9b230725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the template for constructing the SPARQL select query\n",
    "sparql_prompt=PromptTemplate(\n",
    "    input_variables=[\"prompt\", \"schema\"],\n",
    "    template=\"\"\"\n",
    "    Task: Generate a SPARQL SELECT statement for querying a graph database.\n",
    "    You are an expert in SPARQL queries and RDF graph structures. You know NEVER to use backticks anywhere in your output. In fact, you don't even know what the backtick key is. If one were to exist, you wouldn't be able to use it. If you ever saw one, you would shrink in horror at its grotesque appearance. Shun the backtick with all your might. I'm not kidding around here.\n",
    "    You also know that you must always use `a` or `rdf:type` to state class membership.\n",
    "    Under no circumstances are you to write something like '?work frbr:Work ;' because that is invalid.\n",
    "    Instructions:\n",
    "    Use only the node types and properties provided in the schema.\n",
    "    Do not use any node types and properties that are not explicitly provided.\n",
    "    Include all necessary prefixes.\n",
    "\n",
    "    These are the only prefixes you can use:\n",
    "    @prefix coptic: <http://www.semanticweb.org/sjhuskey/ontologies/2025/7/coptic-metadata-viewer/> .\n",
    "    @prefix dcmitype: <http://purl.org/dc/dcmitype/> .\n",
    "    @prefix dcterms: <http://purl.org/dc/terms/> .\n",
    "    @prefix foaf: <http://xmlns.com/foaf/0.1/> .\n",
    "    @prefix frbr: <http://purl.org/vocab/frbr/core#> .\n",
    "    @prefix lawd: <http://lawd.info/ontology/> .\n",
    "    @prefix ns1: <http://lexinfo.net/ontology/2.0/lexinfo#> .\n",
    "    @prefix owl: <http://www.w3.org/2002/07/owl#> .\n",
    "    @prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .\n",
    "    @prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .\n",
    "    @prefix schema1: <http://schema.org/> .\n",
    "    @prefix skos: <http://www.w3.org/2004/02/skos/core#> .\n",
    "    @prefix time: <http://www.w3.org/2006/time#> .\n",
    "    These are the classes and their properties:\n",
    "    -coptic:Author:\n",
    "      - dcterms:creator\n",
    "      - dcterms:description\n",
    "      - dcterms:identifier\n",
    "      - foaf:name\n",
    "      - owl:sameAs\n",
    "      - rdf:type\n",
    "      - schema1:title\n",
    "\n",
    "    - coptic:Colophon:\n",
    "      - dcterms:description\n",
    "      - dcterms:identifier\n",
    "      - dcterms:isPartOf\n",
    "      - dcterms:references\n",
    "      - dcterms:type\n",
    "      - ns1:translation\n",
    "      - rdf:type\n",
    "      - time:hasBeginning\n",
    "      - time:hasEnd\n",
    "\n",
    "    - coptic:Manuscript:\n",
    "      - dcterms:bibliographicCitation\n",
    "      - dcterms:description\n",
    "      - dcterms:hasPart\n",
    "      - dcterms:identifier\n",
    "      - dcterms:isPartOf\n",
    "      - dcterms:medium\n",
    "      - rdf:type\n",
    "      - time:hasBeginning\n",
    "      - time:hasEnd\n",
    "\n",
    "    - coptic:Title:\n",
    "      - dcterms:description\n",
    "      - dcterms:identifier\n",
    "      - dcterms:isPartOf\n",
    "      - dcterms:references\n",
    "      - dcterms:type\n",
    "      - rdf:type\n",
    "\n",
    "    - dcmitype:Collection:\n",
    "      - dcterms:hasPart\n",
    "      - dcterms:identifier\n",
    "      - dcterms:spatial\n",
    "      - rdf:type\n",
    "\n",
    "    - foaf:Person:\n",
    "      - dcterms:identifier\n",
    "      - dcterms:isReferencedBy\n",
    "      - foaf:name\n",
    "      - ns1:transliteration\n",
    "      - rdf:type\n",
    "      - rdfs:label\n",
    "      - schema1:birthPlace\n",
    "      - schema1:gender\n",
    "      - schema1:roleName\n",
    "      - time:hasBeginning\n",
    "      - time:hasEnd\n",
    "\n",
    "    - frbr:Work:\n",
    "      - dcterms:creator\n",
    "      - dcterms:description\n",
    "      - dcterms:identifier\n",
    "      - dcterms:isPartOf\n",
    "      - dcterms:isReferencedBy\n",
    "      - dcterms:temporal\n",
    "      - dcterms:title\n",
    "      - rdf:type\n",
    "      - rdfs:label\n",
    "\n",
    "    - lawd:Place:\n",
    "      - lawd:primaryForm\n",
    "      - rdf:type\n",
    "      - rdfs:label\n",
    "      - skos:exactMatch\n",
    "    \n",
    "    Schema:\n",
    "    {schema}\n",
    "    \n",
    "    Note: Be as concise as possible.\n",
    "    Do not include any explanations or apologies in your responses.\n",
    "    Do not respond to any questions that ask for anything else than for you to construct a SPARQL query.\n",
    "    Do not include any text except the SPARQL query generated.\n",
    "    Do not use backticks.\n",
    "    Do not wrap the SPARQL query in any additional formatting.\n",
    "    Do not use triple backticks.\n",
    "    Do not use ```sparql.\n",
    "\n",
    "    The question is:\n",
    "    {prompt}'\n",
    "    \"\"\")\n",
    "\n",
    "# Create the template for the question-answering prompt\n",
    "qa_prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"prompt\"],\n",
    "    template=\"\"\"\n",
    "    You are a friendly and knowledgeable digital research assistant specializing in Coptic and Greek texts.\n",
    "\n",
    "    Given the structured data below, answer the user’s question in clear, natural language.\n",
    "    Use complete sentences. If multilingual forms are included, identify which language each form belongs to.\n",
    "\n",
    "    Structured data:\n",
    "    {context}\n",
    "\n",
    "    User question:\n",
    "    {prompt}\n",
    "\n",
    "    Answer:\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "59665455",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DualLLMSparqlChain(Runnable):\n",
    "    def __init__(self, sparql_llm, qa_llm, sparql_prompt, qa_prompt, graph):\n",
    "        self.sparql_llm_chain = sparql_prompt | sparql_llm\n",
    "        self.qa_llm_chain = qa_prompt | qa_llm\n",
    "        self.graph = graph\n",
    "\n",
    "    def invoke(self, user_question: str, config=None) -> dict:\n",
    "        # 1. Generate SPARQL using coding-focused LLM\n",
    "        sparql_query = self.sparql_llm_chain.invoke({\n",
    "            \"prompt\": user_question, \n",
    "            \"schema\": self.graph.get_schema\n",
    "        })\n",
    "\n",
    "\n",
    "        # 2. Normalize\n",
    "        sparql_query = self._normalize_sparql(sparql_query)\n",
    "\n",
    "        # 3. Try running query\n",
    "        try:\n",
    "            results = self.graph.query(sparql_query)\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                \"result\": None,\n",
    "                \"error\": str(e),\n",
    "                \"sparql_query\": sparql_query,\n",
    "                \"rows\": []\n",
    "            }\n",
    "\n",
    "        # 4. Format results\n",
    "        rows = [\" | \".join(str(v) for v in row) for row in results]\n",
    "        context = \"\\n\".join(rows)\n",
    "\n",
    "        # 5. Use second LLM for natural language answer\n",
    "        if rows:\n",
    "            answer = self.qa_llm_chain.invoke({\n",
    "                \"prompt\": user_question,\n",
    "                \"context\": context\n",
    "            })\n",
    "        else:\n",
    "            answer = \"No results found.\"\n",
    "\n",
    "        return {\n",
    "            \"result\": answer,\n",
    "            \"sparql_query\": sparql_query,\n",
    "            \"rows\": rows\n",
    "        }\n",
    "\n",
    "    def _normalize_sparql(self, query: str) -> str:\n",
    "        query = query.strip().replace(\"```sparql\", \"\").replace(\"```\", \"\").replace(\"`\", \"\")\n",
    "        if query.upper().startswith(\"WHERE\"):\n",
    "            return \"SELECT * \" + query\n",
    "        return query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1f2402aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama.llms import OllamaLLM\n",
    "\n",
    "# LLMs\n",
    "sparql_llm = OllamaLLM(model=\"codestral:22b\")\n",
    "qa_llm = OllamaLLM(model=\"mistral-small3.2:latest\")\n",
    "\n",
    "# Chain\n",
    "dual_chain = DualLLMSparqlChain(\n",
    "    sparql_llm=sparql_llm,\n",
    "    qa_llm=qa_llm,\n",
    "    sparql_prompt=sparql_prompt,\n",
    "    qa_prompt=qa_prompt,\n",
    "    graph=graph\n",
    ")\n",
    "\n",
    "result = dual_chain.invoke(\"Who wrote 'Sermo asceticus'?\")\n",
    "print(type(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8fc968f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: The text titled \"Sermo asceticus\" is attributed to Stephen of Thebes. His name appears in Coptic as ⲥⲧⲉⲫⲁⲛⲟⲥ and in Greek as Στέφανος.\n",
      "sparql_query: PREFIX coptic: <http://www.semanticweb.org/sjhuskey/ontologies/2025/7/coptic-metadata-viewer/>\n",
      "      PREFIX dcterms: <http://purl.org/dc/terms/>\n",
      "      PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
      "      PREFIX frbr: <http://purl.org/vocab/frbr/core#>\n",
      "\n",
      "      SELECT ?authorName WHERE {\n",
      "        ?work a frbr:Work ;\n",
      "               dcterms:title \"Sermo asceticus\" ;\n",
      "               dcterms:creator ?author .\n",
      "        ?author rdf:type coptic:Author ;\n",
      "                 foaf:name ?authorName .\n",
      "      }\n",
      "rows: ['Stephen of Thebes', 'ⲥⲧⲉⲫⲁⲛⲟⲥ', 'Στέφανος']\n"
     ]
    }
   ],
   "source": [
    "type(result)\n",
    "for k,v in result.items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2706329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the GraphSparqlQAChain with the LLM, prompts, and graph\n",
    "chain = GraphSparqlQAChain.from_llm(\n",
    "    #ChatOpenAI(model=\"gpt-4o-mini\", temperature=0),\n",
    "    OllamaLLM(model=\"mistral-small3.2:latest\", temperature=0),\n",
    "    sparql_select_prompt=sparql_select_prompt,\n",
    "    qa_prompt=qa_prompt,\n",
    "    graph=graph,\n",
    "    verbose=True,\n",
    "    return_intermediate_steps=True,\n",
    "    allow_dangerous_requests=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43c7c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example query to test the chain\n",
    "output = chain.invoke(\"Who is the creator of the work with the title 'Sermo asceticus?'\")  # Example query\n",
    "print(output['result'])  # Print the answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2249f4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = chain.invoke(\"What is known about the 'Encomium of Theodore Archbishop of Antioch\")  # Example query\n",
    "print(output['result'])  # Print the answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f4f8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = chain.invoke(\"What is in the graph about Theodore the Anatolian?\")  # Example query\n",
    "print(output['result'])  # Print the answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57627a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = chain.invoke(\"Please find any text in the graph with the string 'Theodore the Anatolian'.\")  # Example query\n",
    "print(output['result'])  # Print the answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b93c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = chain.invoke(\"Tell me more about title 307\")  # Example query\n",
    "print(output['result'])  # Print the answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c8aa2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = chain.invoke(\"Tell me more about the title with identifier 307\")  # Example query\n",
    "print(output['result'])  # Print the answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385585e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = chain.invoke(\"Which manuscript dcterms:hasPart the title with id 307?\")  # Example query\n",
    "print(output['result'])  # Print the answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90cfa6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "schroeder",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
