{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67fb90c4",
   "metadata": {},
   "source": [
    "# Make Turtles\n",
    "\n",
    "This notebook contains code to turn JSON files downloaded from PAThs into RDF triples serialized as Turtles (.ttl). It uses the [RDFLib](https://github.com/RDFLib/rdflib) library to make the conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f679de7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from rdflib import BNode, Graph, URIRef, Literal, Namespace, URIRef, RDF\n",
    "from rdflib.namespace import RDF, RDFS, DCMITYPE, DCTERMS, FOAF, OWL, SKOS\n",
    "import re\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01de2b52",
   "metadata": {},
   "source": [
    "## Authors\n",
    "\n",
    "We want to end up with turtles like the following example:\n",
    "\n",
    "```\n",
    "<http://paths.uniroma1.it/atlas/authors/11> a coptic:Author ;\n",
    "    dcterms:creator <http://paths.uniroma1.it/atlas/works/253> ;\n",
    "    dcterms:description \"\"\"Probably a native of the Thebaid, Stephen of Thebes is for us a fairly elusive figure. Indeed, no historically reliable pieces of information are available. However, moving from the analysis of the sole composition attributed to him in Coptic, his life and activity seem to be closely related to the monastic environment of Lower Egypt, and specifically to the sites of Scetis, Kellia, and Nitria. \\r\n",
    "A number of possible identifications have been suggested, including that with Stephen the Anchorite (see Lucchesi 2007a and Lucchesi 1998b), with the Stephen mentioned by Palladius in Historia Lausiaca 55.3 (see Dechow 1988; Lucchesi 2007a), and again with a homonymous anchorite celebrated on May 7 in the calendar provided by Abū al-Barakāt in his Lamp of Darkness (see Suciu 2018b, also for an updated status quaestionis).\\r\n",
    "However, in the absence of concluding evidence, all these possibilities remain hypothetical. \\r\n",
    "Indeed, the only firm source of information available is the text itself of the Sermo asceticum (CC0253), a collection of aphorisms and gnomic sentences addressed by an ascetic teacher to his spiritual pupil. Although the Sahidic redaction (probably the original one) is acephalous and fragmentarily preserved – and consequently anonymous – the indirect transmission in Greek, Arabic, Georgian, and Ethiopic seems to attribute the authorship to an Egyptian ascetic named Stephen, who probably lived contemporaneously with Athanasius. This would make Stephen of Thebes one of the earliest (and least known) original authors in Coptic.\\r\n",
    "\"\"\" ;\n",
    "    dcterms:identifier \"11\" ;\n",
    "    owl:sameAs <https://viaf.org/viaf/64111548> ;\n",
    "    foaf:name \"Stephen of Thebes\",\n",
    "        \"ⲥⲧⲉⲫⲁⲛⲟⲥ\"@cop,\n",
    "        \"Στέφανος\"@el .\n",
    "```\n",
    "\n",
    "I'll use as many common metadata terms as possible, but I am going to define an Author class in the COPTIC namespace for the purposes of easy querying. Not every LLM understands the concept of `dcterms:creator`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03620f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ RDF data saved to ../turtles/authors.ttl\n"
     ]
    }
   ],
   "source": [
    "# Load JSON data\n",
    "with open(\"../data/authors.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    authors = json.load(f)\n",
    "\n",
    "# Define namespaces\n",
    "PATHS = Namespace(\"http://paths.uniroma1.it/atlas/\")\n",
    "FRBR = Namespace(\"http://purl.org/vocab/frbr/core#\")\n",
    "SCHEMA = Namespace(\"http://schema.org/\")\n",
    "COPTIC = Namespace(\"http://www.semanticweb.org/sjhuskey/ontologies/2025/7/coptic-metadata-viewer/\")\n",
    "\n",
    "# Create graph\n",
    "g = Graph()\n",
    "g.bind(\"dcterms\", DCTERMS)\n",
    "g.bind(\"foaf\", FOAF)\n",
    "g.bind(\"owl\", OWL)\n",
    "g.bind(\"paths\", PATHS)\n",
    "g.bind(\"schema1\", SCHEMA)\n",
    "g.bind(\"coptic\", COPTIC)\n",
    "\n",
    "for author in authors:\n",
    "    core = author.get(\"core\", {})\n",
    "    backlinks = author.get(\"backlinks\", {})\n",
    "    plugins = author.get(\"plugins\", {})\n",
    "\n",
    "    aid = core[\"id\"][\"val\"]\n",
    "    author_uri = PATHS[f\"authors/{aid}\"]\n",
    "\n",
    "    g.add((author_uri, RDF.type, COPTIC.Author))\n",
    "    g.add((author_uri, DCTERMS.identifier, Literal(aid)))\n",
    "\n",
    "    # Add simple string fields using dcterms\n",
    "    if (name := core.get(\"name\", {}).get(\"val\")):\n",
    "        g.add((author_uri, FOAF.name, Literal(name)))\n",
    "    if (copticname := core.get(\"copticname\", {}).get(\"val\")):\n",
    "        g.add((author_uri, FOAF.name, Literal(copticname, lang=\"cop\")))\n",
    "    if (greekname := core.get(\"greekname\", {}).get(\"val\")):\n",
    "        g.add((author_uri, FOAF.name, Literal(greekname, lang=\"el\")))\n",
    "    if (title := core.get(\"title\", {}).get(\"val\")):\n",
    "        g.add((author_uri, SCHEMA.title, Literal(title)))\n",
    "    if (bio := core.get(\"bio\", {}).get(\"val\")):\n",
    "        g.add((author_uri, DCTERMS.description, Literal(bio)))\n",
    "    if (viaf := core.get(\"viaf\", {}).get(\"val\")):\n",
    "        if isinstance(viaf, str) and viaf.isdigit():\n",
    "            g.add((author_uri, OWL.sameAs, URIRef(f\"https://viaf.org/viaf/{viaf}\")))\n",
    "    \n",
    "\n",
    "    # Link to works (via backlinks)\n",
    "    if isinstance(author.get(\"backlinks\"), dict):\n",
    "        works_backlink = author[\"backlinks\"].get(\"paths__works\")\n",
    "        if isinstance(works_backlink, dict):\n",
    "            for work in works_backlink.get(\"data\", []):\n",
    "                if isinstance(work, dict) and \"id\" in work:\n",
    "                    work_id = work[\"id\"]\n",
    "                    work_uri = PATHS[f\"works/{work_id}\"]\n",
    "\n",
    "                    # Link author to work\n",
    "                    g.add((author_uri, DCTERMS.creator , work_uri))\n",
    "                    g.add((work_uri, DCTERMS.creator , author_uri))\n",
    "\n",
    "# Save graph as Turtle\n",
    "g.serialize(destination=\"../turtles/authors.ttl\", format=\"turtle\")\n",
    "print(\"✅ RDF data saved to ../turtles/authors.ttl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3209f90",
   "metadata": {},
   "source": [
    "## Collections\n",
    "\n",
    "## Collections\n",
    "\n",
    "We want to generate turtles like this:\n",
    "\n",
    "```\n",
    "<http://paths.uniroma1.it/atlas/collections/20> a dcmitype:Collection ;\n",
    "    dcterms:hasPart <http://paths.uniroma1.it/atlas/manuscripts/2200>,\n",
    "        <http://paths.uniroma1.it/atlas/manuscripts/2201>,\n",
    "        <http://paths.uniroma1.it/atlas/manuscripts/2203>,\n",
    "        <http://paths.uniroma1.it/atlas/manuscripts/24>,\n",
    "        <http://paths.uniroma1.it/atlas/manuscripts/3223>,\n",
    "        <http://paths.uniroma1.it/atlas/manuscripts/324>,\n",
    "        <http://paths.uniroma1.it/atlas/manuscripts/378>,\n",
    "        <http://paths.uniroma1.it/atlas/manuscripts/3972>,\n",
    "        <http://paths.uniroma1.it/atlas/manuscripts/3973>,\n",
    "        <http://paths.uniroma1.it/atlas/manuscripts/3974>,\n",
    "        <http://paths.uniroma1.it/atlas/manuscripts/3975>,\n",
    "        <http://paths.uniroma1.it/atlas/manuscripts/3979>,\n",
    "        <http://paths.uniroma1.it/atlas/manuscripts/3981>,\n",
    "        <http://paths.uniroma1.it/atlas/manuscripts/3982>,\n",
    "        <http://paths.uniroma1.it/atlas/manuscripts/424>,\n",
    "        <http://paths.uniroma1.it/atlas/manuscripts/6255>,\n",
    "        <http://paths.uniroma1.it/atlas/manuscripts/6256>,\n",
    "        <http://paths.uniroma1.it/atlas/manuscripts/6788>,\n",
    "        <http://paths.uniroma1.it/atlas/manuscripts/687>,\n",
    "        <http://paths.uniroma1.it/atlas/manuscripts/692>,\n",
    "        <http://paths.uniroma1.it/atlas/manuscripts/709> ;\n",
    "    dcterms:identifier \"20\",\n",
    "        \"BS.OCT\" ;\n",
    "    dcterms:spatial \"Berlin\",\n",
    "        \"Germany\",\n",
    "        \"Staatsbibliothek zu Berlin - Preußischer Kulturbesitz\" ;\n",
    "    schema1:location \"Berlin\",\n",
    "        \"Germany\" ;\n",
    "    schema1:name \"Germany, Berlin, Staatsbibliothek zu Berlin - Preußischer Kulturbesitz, Ms. or. oct.\",\n",
    "        \"Staatsbibliothek zu Berlin - Preußischer Kulturbesitz\" .\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b037d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ RDF data saved to ../turtles/collections.ttl\n"
     ]
    }
   ],
   "source": [
    "# Load JSON data\n",
    "with open(\"../data/collections.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    collections = json.load(f)\n",
    "\n",
    "def get_place_uri_and_node(label, class_uri):\n",
    "    place_id = label.lower().replace(\" \", \"-\").replace(\",\", \"\").replace(\".\", \"\")\n",
    "    place_uri = PATHS[f\"places/{place_id}\"]\n",
    "    g.add((place_uri, RDF.type, class_uri))\n",
    "    g.add((place_uri, RDFS.label, Literal(label)))\n",
    "    return place_uri\n",
    "\n",
    "# Define namespaces\n",
    "PATHS = Namespace(\"http://paths.uniroma1.it/atlas/\")\n",
    "FRBR = Namespace(\"http://purl.org/vocab/frbr/core#\")\n",
    "SCHEMA = Namespace(\"http://schema.org/\")\n",
    "\n",
    "# Create graph\n",
    "g = Graph()\n",
    "g.bind(\"dcmitype\", DCMITYPE)\n",
    "g.bind(\"dcterms\", DCTERMS)\n",
    "g.bind(\"foaf\", FOAF)\n",
    "g.bind(\"owl\", OWL)\n",
    "g.bind(\"frbr\", FRBR)\n",
    "g.bind(\"paths\", PATHS)\n",
    "g.bind(\"schema1\", SCHEMA)\n",
    "\n",
    "for collection in collections:\n",
    "    core = collection.get(\"core\", {})\n",
    "    backlinks = collection.get(\"backlinks\", {})\n",
    "\n",
    "    cid = core[\"id\"][\"val\"]\n",
    "    collection_uri = PATHS[f\"collections/{cid}\"]\n",
    "\n",
    "    g.add((collection_uri, RDF.type, DCMITYPE.Collection))\n",
    "    g.add((collection_uri, DCTERMS.identifier, Literal(cid)))\n",
    "\n",
    "    # Add simple string fields using dcterms\n",
    "    if (cmclname := core.get(\"cmclname\", {}).get(\"val\")):\n",
    "        g.add((collection_uri, DCTERMS.identifier, Literal(cmclname)))\n",
    "    if institution := core.get(\"institution\", {}).get(\"val\"):\n",
    "        g.add((collection_uri, SCHEMA.name, Literal(institution)))\n",
    "    if (fullname := core.get(\"fullname\", {}).get(\"val\")):\n",
    "        g.add((collection_uri, SCHEMA.name, Literal(fullname)))\n",
    "    if town := core.get(\"town\", {}).get(\"val\"):\n",
    "        g.add((collection_uri, SCHEMA.location, Literal(town)))\n",
    "    if country := core.get(\"country\", {}).get(\"val\"):\n",
    "        g.add((collection_uri, SCHEMA.location, Literal(country)))\n",
    "\n",
    "    # Link to works (via backlinks)\n",
    "    if isinstance(collection.get(\"backlinks\"), dict):\n",
    "        manuscripts_backlinks = collection[\"backlinks\"].get(\"paths__manuscripts\")\n",
    "        if isinstance(manuscripts_backlinks, dict):\n",
    "            for manuscript in manuscripts_backlinks.get(\"data\", []):\n",
    "                if isinstance(manuscript, dict) and \"id\" in manuscript:\n",
    "                    manuscript_id = manuscript[\"id\"]\n",
    "                    manuscript_uri = PATHS[f\"manuscripts/{manuscript_id}\"]\n",
    "                    g.add((collection_uri, DCTERMS.hasPart, manuscript_uri))\n",
    "                    g.add((manuscript_uri, DCTERMS.isPartOf, collection_uri))\n",
    "\n",
    "# Save graph as Turtle\n",
    "g.serialize(destination=\"../turtles/collections.ttl\", format=\"turtle\")\n",
    "print(\"✅ RDF data saved to ../turtles/collections.ttl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ece6800",
   "metadata": {},
   "source": [
    "## Manuscripts\n",
    "\n",
    "We want to end up with output like the following:\n",
    "\n",
    "```\n",
    "<http://paths.uniroma1.it/atlas/manuscripts/3493> a coptic:Manuscript ;\n",
    "    dcterms:bibliographicCitation [ dcterms:creator \"Behlmer, H.\" ;\n",
    "            dcterms:description \"190\",\n",
    "                \"24-25\" ;\n",
    "            dcterms:extent \"11-27\" ;\n",
    "            dcterms:issued \"2003\" ;\n",
    "            dcterms:title \"Streiflichter auf die christliche Besiedlung Thebens: Koptische Ostraka aus dem Grab des Senneferi (TT 99)\" ],\n",
    "        [ dcterms:creator \"Behlmer, H.\" ;\n",
    "            dcterms:description \"190\",\n",
    "                \"24-25\" ;\n",
    "            dcterms:extent \"11-27\" ;\n",
    "            dcterms:issued \"2003\" ;\n",
    "            dcterms:title \"Streiflichter auf die christliche Besiedlung Thebens: Koptische Ostraka aus dem Grab des Senneferi (TT 99)\" ],\n",
    "        [ dcterms:creator \"Behlmer, H.\" ;\n",
    "            dcterms:description \"190\",\n",
    "                \"24-25\" ;\n",
    "            dcterms:extent \"11-27\" ;\n",
    "            dcterms:issued \"2003\" ;\n",
    "            dcterms:title \"Streiflichter auf die christliche Besiedlung Thebens: Koptische Ostraka aus dem Grab des Senneferi (TT 99)\" ],\n",
    "        [ dcterms:creator \"Behlmer, H.\" ;\n",
    "            dcterms:description \"190\",\n",
    "                \"24-25\" ;\n",
    "            dcterms:extent \"11-27\" ;\n",
    "            dcterms:issued \"2003\" ;\n",
    "            dcterms:title \"Streiflichter auf die christliche Besiedlung Thebens: Koptische Ostraka aus dem Grab des Senneferi (TT 99)\" ],\n",
    "        [ dcterms:creator \"Behlmer, H.\" ;\n",
    "            dcterms:description \"190\",\n",
    "                \"24-25\" ;\n",
    "            dcterms:extent \"11-27\" ;\n",
    "            dcterms:issued \"2003\" ;\n",
    "            dcterms:title \"Streiflichter auf die christliche Besiedlung Thebens: Koptische Ostraka aus dem Grab des Senneferi (TT 99)\" ],\n",
    "        [ dcterms:creator \"Behlmer, H.\" ;\n",
    "            dcterms:description \"190\",\n",
    "                \"24-25\" ;\n",
    "            dcterms:extent \"11-27\" ;\n",
    "            dcterms:issued \"2003\" ;\n",
    "            dcterms:title \"Streiflichter auf die christliche Besiedlung Thebens: Koptische Ostraka aus dem Grab des Senneferi (TT 99)\" ] ;\n",
    "    dcterms:hasPart \"Unidentified literary text\" ;\n",
    "    dcterms:identifier \"3493\" ;\n",
    "    dcterms:medium \"ostrakon\",\n",
    "        \"stone\" ;\n",
    "    time:hasBeginning \"501\" ;\n",
    "    time:hasEnd \"650\" .\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7eb33d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ RDF data saved to ../turtles/manuscripts.ttl\n"
     ]
    }
   ],
   "source": [
    "# Namespaces\n",
    "PATHS = Namespace(\"http://paths.uniroma1.it/atlas/\")\n",
    "TIME = Namespace(\"http://www.w3.org/2006/time#\")\n",
    "COPTIC = Namespace(\"http://www.semanticweb.org/sjhuskey/ontologies/2025/7/coptic-metadata-viewer/\")\n",
    "\n",
    "g = Graph()\n",
    "g.bind(\"dcterms\", DCTERMS)\n",
    "g.bind(\"paths\", PATHS)\n",
    "g.bind(\"time\", TIME)\n",
    "g.bind(\"coptic\", COPTIC)\n",
    "\n",
    "# Load JSON\n",
    "with open(\"../data/manuscripts.json\", encoding=\"utf-8\") as f:\n",
    "    manuscripts = json.load(f)\n",
    "\n",
    "for m in manuscripts:\n",
    "    core = m.get(\"core\", {})\n",
    "    plugins = m.get(\"plugins\", [])\n",
    "\n",
    "    # Function for looping through plugins\n",
    "    def get_plugin_data(plugins, key):\n",
    "        if isinstance(plugins, list):\n",
    "            for plugin in plugins:\n",
    "                if isinstance(plugin, dict):\n",
    "                    maybe_data = plugin.get(key)\n",
    "                    if maybe_data and \"data\" in maybe_data:\n",
    "                        data = maybe_data[\"data\"]\n",
    "                        if isinstance(data, dict):\n",
    "                            return list(data.values())\n",
    "                        elif isinstance(data, list):\n",
    "                            return data\n",
    "        elif isinstance(plugins, dict):\n",
    "            maybe_data = plugins.get(key)\n",
    "            if maybe_data and \"data\" in maybe_data:\n",
    "                data = maybe_data[\"data\"]\n",
    "                if isinstance(data, dict):\n",
    "                    return list(data.values())\n",
    "                elif isinstance(data, list):\n",
    "                    return data\n",
    "        return []\n",
    "\n",
    "    \n",
    "    mid = core.get(\"id\", {}).get(\"val\")\n",
    "    if not mid:\n",
    "        continue\n",
    "\n",
    "    m_uri = PATHS[f\"manuscripts/{mid}\"]\n",
    "    g.add((m_uri, RDF.type, COPTIC.Manuscript))\n",
    "    g.add((m_uri, DCTERMS.identifier, Literal(mid)))\n",
    "\n",
    "    def add_literal(field, predicate):\n",
    "        val = core.get(field, {}).get(\"val\")\n",
    "        if val:\n",
    "            g.add((m_uri, predicate, Literal(val)))\n",
    "    \n",
    "    # Get identifiers\n",
    "    id_fields = {\n",
    "    \"cmclid\": \"CMCL\",\n",
    "    \"tm\": \"TM\",\n",
    "    \"ldab\": \"LDAB\",\n",
    "    \"lcbm\": \"LCBM\"\n",
    "    }\n",
    "\n",
    "    # Build the dictionary\n",
    "    identifiers = {}\n",
    "    for field, label in id_fields.items():\n",
    "        val = core.get(field, {}).get(\"val\")\n",
    "        if val:  # Only include non-null values\n",
    "            identifiers[label] = val\n",
    "    \n",
    "    # Add identifiers to the graph\n",
    "    for id_type, id_value in identifiers.items():\n",
    "        id_node = BNode()\n",
    "        g.add((manuscript_uri, DCTERMS.identifier, id_node))\n",
    "        g.add((id_node, RDF.value, Literal(id_value)))\n",
    "        g.add((id_node, DCTERMS.publisher, Literal(id_type)))\n",
    "\n",
    "\n",
    "    # Descriptions\n",
    "    add_literal(\"modernhistory\", DCTERMS.description)\n",
    "    add_literal(\"gennotes\", DCTERMS.description)\n",
    "\n",
    "    # Contents → hasPart\n",
    "    contents = core.get(\"contents\", {}).get(\"val\")\n",
    "    if contents:\n",
    "        g.add((m_uri, DCTERMS.hasPart, Literal(contents)))\n",
    "\n",
    "    # Chrono range → temporal (both as separate strings)\n",
    "    if (chronofrom := core.get(\"chronofrom\", {}).get(\"val\")):\n",
    "        g.add((m_uri, TIME.hasBeginning, Literal(chronofrom)))\n",
    "    if (chronoto := core.get(\"chronoto\", {}).get(\"val\")):\n",
    "        g.add((m_uri, TIME.hasEnd, Literal(chronoto)))\n",
    "    # Typology → has_type\n",
    "    for field in [\"bookform\", \"writingsupport\"]:\n",
    "        val = core.get(field, {}).get(\"val\")\n",
    "        if val:\n",
    "            g.add((m_uri, DCTERMS.medium, Literal(val)))\n",
    "\n",
    "    # Shelfmark block\n",
    "    for shelf in get_plugin_data(plugins, \"paths__m_shelfmarks\"):\n",
    "        sid = shelf.get(\"id\", {}).get(\"val\")\n",
    "        if not sid:\n",
    "            continue\n",
    "        shelf_uri = PATHS[f\"shelfmark/{sid}\"]\n",
    "        collection_id = shelf.get(\"collection\", {}).get(\"val\")\n",
    "        if not collection_id:\n",
    "            continue\n",
    "        collection_uri = PATHS[f\"collections/{collection_id}\"]\n",
    "        g.add((manuscript_uri, DCTERMS.isPartOf, collection_uri))\n",
    "        g.add((collection_uri, DCTERMS.hasPart, manuscript_uri))\n",
    "\n",
    "        # Full shelf string\n",
    "        if (full := shelf.get(\"fullsegnat\", {}).get(\"val\")):\n",
    "            g.add((manuscript_uri, DCTERMS.identifier, Literal(full)))\n",
    "\n",
    "    # Bibliography block\n",
    "    for bib_item in get_plugin_data(plugins, \"paths__m_biblio\"):\n",
    "        bib_uri = BNode()\n",
    "        g.add((m_uri, DCTERMS.bibliographicCitation, bib_uri))\n",
    "        \n",
    "        # Add bibliographic details\n",
    "        if (short := bib_item.get(\"short\", {}).get(\"val\")):\n",
    "            g.add((bib_uri, DCTERMS.description, Literal(short)))\n",
    "        if (authors := bib_item.get(\"authors\", {}).get(\"val\")):\n",
    "            g.add((bib_uri, DCTERMS.creator, Literal(authors)))\n",
    "        if (title := bib_item.get(\"title\", {}).get(\"val\")):\n",
    "            g.add((bib_uri, DCTERMS.title, Literal(title)))\n",
    "        if (details := bib_item.get(\"details\", {}).get(\"val\")):\n",
    "            g.add((bib_uri, DCTERMS.description, Literal(details)))\n",
    "        if (pages := bib_item.get(\"pages\", {}).get(\"val\")):\n",
    "            g.add((bib_uri, DCTERMS.extent, Literal(pages)))\n",
    "        if (series := bib_item.get(\"series\", {}).get(\"val\")):\n",
    "            g.add((bib_uri, DCTERMS.isPartOf, Literal(series)))\n",
    "        if (year := bib_item.get(\"year\", {}).get(\"val\")):\n",
    "            g.add((bib_uri, DCTERMS.issued, Literal(year)))\n",
    "        \n",
    "\n",
    "# Serialize to Turtle\n",
    "g.serialize(\"../turtles/manuscripts.ttl\", format=\"turtle\")\n",
    "print(\"✅ RDF data saved to ../turtles/manuscripts.ttl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5e94ef",
   "metadata": {},
   "source": [
    "## Persons\n",
    "\n",
    "We want output like this:\n",
    "\n",
    "```\n",
    "<http://paths.uniroma1.it/atlas/persons/100> a foaf:Person ;\n",
    "    rdfs:label \"Cyrus\" ;\n",
    "    ns1:transliteration \"Kyre\" ;\n",
    "    dcterms:identifier \"100\" ;\n",
    "    schema1:gender \"male\" ;\n",
    "    schema1:roleName \"donor\" ;\n",
    "    time:hasBeginning \"851\" ;\n",
    "    time:hasEnd \"950\" ;\n",
    "    foaf:name \"ⲁⲡⲁ ⲕⲩⲣⲉ\"@cop .\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "627054de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved RDF data to ../turtles/persons.ttl\n"
     ]
    }
   ],
   "source": [
    "# Define Namespaces\n",
    "PATHS = Namespace(\"http://paths.uniroma1.it/atlas/\")\n",
    "SCHEMA = Namespace(\"http://schema.org/\")\n",
    "LEXINFO = Namespace(\"http://lexinfo.net/ontology/2.0/lexinfo#\")\n",
    "TIME = Namespace(\"http://www.w3.org/2006/time#\")\n",
    "\n",
    "g = Graph()\n",
    "g.bind(\"paths\", PATHS)\n",
    "g.bind(\"foaf\", FOAF)\n",
    "g.bind(\"dcterms\", DCTERMS)\n",
    "g.bind(\"owl\", OWL)\n",
    "g.bind(\"schema\", SCHEMA)\n",
    "g.bind(\"lexinfo\", LEXINFO)\n",
    "g.bind(\"time\", TIME)\n",
    "\n",
    "# Load person records (replace this with actual file read if needed)\n",
    "with open(\"../data/persons.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    persons = json.load(f)\n",
    "\n",
    "for person in persons:\n",
    "    core = person.get(\"core\", {})\n",
    "    plugins = person.get(\"plugins\", {})\n",
    "    \n",
    "    # Initialize empty list in case no nameforms found\n",
    "    nameforms_data = {}\n",
    "\n",
    "    # Handle plugins being either dict or list\n",
    "    if isinstance(plugins, dict):\n",
    "        nameforms_data = (\n",
    "            plugins.get(\"paths__m_nameforms\", {})\n",
    "            .get(\"data\", {})\n",
    "        )\n",
    "    elif isinstance(plugins, list):\n",
    "        for p in plugins:\n",
    "            if isinstance(p, dict) and \"paths__m_nameforms\" in p:\n",
    "                nameforms_data = (\n",
    "                    p.get(\"paths__m_nameforms\", {})\n",
    "                    .get(\"data\", {})\n",
    "                )\n",
    "                break  # Found it, stop looking\n",
    "    \n",
    "    manual_links = person.get(\"manualLinks\", {})\n",
    "    manuallinks_data = list(manual_links.values()) if isinstance(manual_links, dict) else []\n",
    "\n",
    "    pid = core.get(\"id\", {}).get(\"val\")\n",
    "    if not pid:\n",
    "        continue\n",
    "\n",
    "    \n",
    "    person_uri = PATHS[f\"persons/{pid}\"]\n",
    "    g.add((person_uri, RDF.type, FOAF.Person))\n",
    "    g.add((person_uri, DCTERMS.identifier, Literal(pid)))\n",
    "\n",
    "    # foaf:name\n",
    "    name = core.get(\"name\", {}).get(\"val\")\n",
    "    if name:\n",
    "        g.add((person_uri, RDFS.label, Literal(name)))\n",
    "\n",
    "    # copt:profession\n",
    "    if (prof := core.get(\"profession\", {}).get(\"val\")):\n",
    "        g.add((person_uri, SCHEMA.roleName, Literal(prof)))\n",
    "\n",
    "    # type → e.g., copyist, scribe, etc.\n",
    "    if (ptype := core.get(\"type\", {}).get(\"val\")):\n",
    "        g.add((person_uri, SCHEMA.roleName, Literal(ptype)))\n",
    "\n",
    "    # date range\n",
    "    datefrom = core.get(\"datefrom\", {}).get(\"val\")\n",
    "    dateto = core.get(\"dateto\", {}).get(\"val\")\n",
    "    if datefrom:\n",
    "        g.add((person_uri, TIME.hasBeginning, Literal(datefrom)))\n",
    "    if dateto and dateto != datefrom:\n",
    "        g.add((person_uri, TIME.hasEnd, Literal(dateto)))\n",
    "\n",
    "    # sex\n",
    "    if (sex := core.get(\"sex\", {}).get(\"val\")):\n",
    "        g.add((person_uri, SCHEMA.gender, Literal(sex)))\n",
    "\n",
    "    # place of birth\n",
    "    if (pb := core.get(\"placebirth\", {}).get(\"val\")):\n",
    "        place_uri = PATHS[f\"places/{pb}\"]\n",
    "        g.add((person_uri, SCHEMA.birthPlace, place_uri))\n",
    "\n",
    "    for nf_id, nf_record in nameforms_data.items():\n",
    "        nameform = nf_record.get(\"nameform\", {}).get(\"val\")\n",
    "        language = nf_record.get(\"language\", {}).get(\"val\")\n",
    "        translit = nf_record.get(\"transliteration\", {}).get(\"val\")\n",
    "\n",
    "        if nameform:\n",
    "            lang_tag = {\"Coptic\": \"cop\", \"Greek\": \"el\"}.get(language, None)\n",
    "            if lang_tag:\n",
    "                g.add((person_uri, FOAF.name, Literal(nameform, lang=lang_tag)))\n",
    "            else:\n",
    "                g.add((person_uri, FOAF.name, Literal(nameform)))\n",
    "\n",
    "        if translit:\n",
    "            g.add((person_uri, LEXINFO.transliteration, Literal(translit)))\n",
    "\n",
    "    # colophon links (manualLinks)\n",
    "    for mlink in manuallinks_data:\n",
    "        if mlink.get(\"tb_stripped\") == \"colophons\":\n",
    "            col_id = mlink.get(\"ref_id\")\n",
    "            col_uri = PATHS[f\"colophons/{col_id}\"]\n",
    "            g.add((person_uri, DCTERMS.isReferencedBy, col_uri))\n",
    "            g.add((col_uri, DCTERMS.references, person_uri))\n",
    "\n",
    "# Serialize\n",
    "g.serialize(\"../turtles/persons.ttl\", format=\"turtle\")\n",
    "print(\"✅ Saved RDF data to ../turtles/persons.ttl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c3e815",
   "metadata": {},
   "source": [
    "## Works\n",
    "\n",
    "We want output like this:\n",
    "\n",
    "```\n",
    "<http://paths.uniroma1.it/atlas/works/966> a frbr:Work ;\n",
    "    dcterms:identifier \"966\",\n",
    "        \"cc0969\" ;\n",
    "    dcterms:isPartOf <http://paths.uniroma1.it/atlas/manuscripts/393> ;\n",
    "    dcterms:temporal \"“Classical” translations – acts of councils and Canones (end of 4th-6th cent.)\" ;\n",
    "    dcterms:title \"Collectio Nicaena C\" .\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e709961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved RDF data to ../turtles/works.ttl\n"
     ]
    }
   ],
   "source": [
    "# Namespaces\n",
    "PATHS = Namespace(\"http://paths.uniroma1.it/atlas/\")\n",
    "SCHEMA = Namespace(\"http://schema.org/\")\n",
    "FRBR = Namespace(\"http://purl.org/vocab/frbr/core#\")\n",
    "\n",
    "g = Graph()\n",
    "g.bind(\"paths\", PATHS)\n",
    "g.bind(\"dcterms\", DCTERMS)\n",
    "g.bind(\"rdfs\", RDFS)\n",
    "g.bind(\"schema\", SCHEMA)\n",
    "g.bind(\"frbr\", FRBR)\n",
    "\n",
    "def extract_cmcl_number(where_clause):\n",
    "    match = re.search(r'cc0*(\\d+)', where_clause)\n",
    "    return match.group(1) if match else None\n",
    "\n",
    "# Load JSON\n",
    "with open(\"../data/works.json\", encoding=\"utf-8\") as f:\n",
    "    works = json.load(f)\n",
    "\n",
    "for work in works:\n",
    "    core = work.get(\"core\", {})\n",
    "    # Normalize plugins into a dict (even if it's wrapped in a list)\n",
    "    raw_plugins = work.get(\"plugins\", {})\n",
    "    if isinstance(raw_plugins, list):\n",
    "        # Look for the first dict in the list\n",
    "        plugins = next((item for item in raw_plugins if isinstance(item, dict)), {})\n",
    "    else:\n",
    "        plugins = raw_plugins\n",
    "    # Normalize links into a dict (even if it's wrapped in a list)\n",
    "    raw_links = work.get(\"links\", {})\n",
    "    if isinstance(raw_links, list):\n",
    "        # Look for the first dict in the list\n",
    "        links = next((item for item in raw_links if isinstance(item, dict)), {})\n",
    "    else:\n",
    "        links = raw_links\n",
    "    raw_manual_links = work.get(\"manualLinks\", {})\n",
    "    if isinstance(raw_manual_links, list):\n",
    "        # Look for the first dict in the list\n",
    "        manual_links = next((item for item in raw_manual_links if isinstance(item, dict)), {})\n",
    "    else:\n",
    "        manual_links = raw_manual_links\n",
    "\n",
    "    wid = core.get(\"id\", {}).get(\"val\")\n",
    "    if not wid:\n",
    "        continue\n",
    "\n",
    "    work_uri = PATHS[f\"works/{wid}\"]\n",
    "    g.add((work_uri, RDF.type, FRBR.Work))\n",
    "    g.add((work_uri, DCTERMS.identifier, Literal(wid)))\n",
    "\n",
    "    # Title\n",
    "    if (title := core.get(\"title\", {}).get(\"val\")):\n",
    "        g.add((work_uri, DCTERMS.title, Literal(title)))\n",
    "\n",
    "    # Clavis Coptica ID\n",
    "    if (clavis := core.get(\"cmcl\", {}).get(\"val\")):\n",
    "        g.add((work_uri, DCTERMS.identifier, Literal(clavis)))\n",
    "\n",
    "    # Literary period\n",
    "    if (period := core.get(\"litperiod\", {}).get(\"val\")):\n",
    "        g.add((work_uri, DCTERMS.temporal, Literal(period)))\n",
    "\n",
    "    # Notes\n",
    "    if (notes := core.get(\"notes\", {}).get(\"val\")):\n",
    "        g.add((work_uri, DCTERMS.description, Literal(notes)))\n",
    "\n",
    "    \n",
    "    # Authorship: link to pre-existing person URIs\n",
    "    author_data = plugins.get(\"paths__m_wkauthors\", {}).get(\"data\", [])\n",
    "    for author in author_data:\n",
    "        author_id = author.get(\"author\", {}).get(\"val\")\n",
    "        author_type = author.get(\"type\", {}).get(\"val\")\n",
    "        if author_id:\n",
    "            author_uri = PATHS[f\"authors/{author_id}\"]\n",
    "            g.add((work_uri, DCTERMS.creator, author_uri))\n",
    "            g.add((author_uri, DCTERMS.creator, work_uri))\n",
    "            if author_type == \"creator\":\n",
    "                g.add((work_uri, RDFS.label, Literal(\"established authorship\")))\n",
    "            if author_type == \"stated\":\n",
    "                g.add((work_uri, RDFS.label, Literal(\"stated authorship\")))\n",
    "\n",
    "    # Manuscript backlinks\n",
    "    for entry in manual_links.values():\n",
    "        if entry.get(\"tb_stripped\") == \"manuscripts\":\n",
    "            mid = entry.get(\"ref_id\")\n",
    "            if mid:\n",
    "                m_uri = PATHS[f\"manuscripts/{mid}\"]\n",
    "                g.add((work_uri, DCTERMS.isPartOf, m_uri))\n",
    "                g.add((m_uri, DCTERMS.hasPart, work_uri))    \n",
    "\n",
    "# Output\n",
    "g.serialize(\"../turtles/works.ttl\", format=\"turtle\")\n",
    "print(\"✅ Saved RDF data to ../turtles/works.ttl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e477f8",
   "metadata": {},
   "source": [
    "## Titles\n",
    "\n",
    "We want output like this:\n",
    "\n",
    "```\n",
    "<http://paths.uniroma1.it/atlas/titles/1041> a coptic:Title ;\n",
    "    dcterms:description \"The title is clearly separated by dotted lines on top and at the bottom of the page.\",\n",
    "        \"ⲛⲉⲛⲧⲟⲗⲏ ⲛⲡⲉⲛⲙⲉⲣⲓⲧ ⲛ̄ⲉⲓⲱⲧ ⲁⲡⲁ ⲁⲛⲟⲩⲡ ⲛ̄ⲛⲉ̣ⲣ̣ⲧ̣ⲏ̣ ϩⲛ ⲟⲩⲉⲓⲣⲏⲛⲏ ϩⲁⲙⲏⲛ:\"@cop,\n",
    "        \"The commandments of our beloved Father Apa Anoup of Nerte. In peace Amen\"@en ;\n",
    "    dcterms:identifier \"1041\",\n",
    "        \"ccT0814-I\" ;\n",
    "    dcterms:isPartOf <http://paths.uniroma1.it/atlas/manuscripts/870> ;\n",
    "    dcterms:type \"title\" .\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f60a2d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved RDF data to ../turtles/titles.ttl\n"
     ]
    }
   ],
   "source": [
    "# Replace this with your actual sample records (truncated here for brevity)\n",
    "with open(\"../data/titles.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    titles_data = json.load(f)\n",
    "    \n",
    "# Namespaces\n",
    "PATHS = Namespace(\"http://paths.uniroma1.it/atlas/\")\n",
    "SCHEMA = Namespace(\"http://schema.org/\")\n",
    "LEXINFO = Namespace(\"http://lexinfo.net/ontology/2.0/lexinfo#\")\n",
    "COPTIC = Namespace(\"http://www.semanticweb.org/sjhuskey/ontologies/2025/7/coptic-metadata-viewer/\")\n",
    "\n",
    "# Create graph\n",
    "g = Graph()\n",
    "g.bind(\"dcterms\", DCTERMS)\n",
    "g.bind(\"paths\", PATHS)\n",
    "g.bind(\"schema\", SCHEMA)\n",
    "g.bind(\"lexinfo\", LEXINFO)\n",
    "g.bind(\"coptic\", COPTIC)\n",
    "\n",
    "# Helper to extract manuscript ID from 'where'\n",
    "def extract_id(where_clause):\n",
    "    match = re.search(r\"id\\|=\\|(\\d+)\", where_clause)\n",
    "    return match.group(1) if match else None\n",
    "\n",
    "def extract_cmcl_number(where_clause):\n",
    "    match = re.search(r'cc0*(\\d+)', where_clause)\n",
    "    return match.group(1) if match else None\n",
    "\n",
    "for record in titles_data:\n",
    "    core = record.get(\"core\", {})\n",
    "    links = record.get(\"links\", {})\n",
    "    plugins = record.get(\"plugins\", {})\n",
    "\n",
    "    title_id = core.get(\"id\", {}).get(\"val\")\n",
    "    if not title_id:\n",
    "        continue\n",
    "\n",
    "    title_uri = PATHS[f\"titles/{title_id}\"]\n",
    "    g.add((title_uri, RDF.type, COPTIC.Title))\n",
    "    g.add((title_uri, DCTERMS.type, Literal(\"title\")))\n",
    "    g.add((title_uri, DCTERMS.identifier, Literal(title_id)))\n",
    "    # Add simple string fields using dcterms\n",
    "    if (description := core.get(\"description\", {}).get(\"val\")):\n",
    "        g.add((title_uri, DCTERMS.description, Literal(description)))\n",
    "    if (cc := core.get(\"cc\", {}).get(\"val\")):\n",
    "        g.add((title_uri, DCTERMS.identifier, Literal(cc)))\n",
    "    if (msid := core.get(\"msid\", {}).get(\"val\")):\n",
    "        m_uri = PATHS[f\"manuscripts/{msid}\"]\n",
    "        g.add((m_uri, DCTERMS.hasPart, title_uri))\n",
    "        g.add((title_uri, DCTERMS.isPartOf, m_uri))\n",
    "    if (text := core.get(\"text\", {}).get(\"val\")):\n",
    "        g.add((title_uri, DCTERMS.description, Literal(text, lang=\"cop\")))\n",
    "    if (translation := core.get(\"translation\", {}).get(\"val\")):\n",
    "        g.add((title_uri, DCTERMS.description, Literal(translation, lang=\"en\")))\n",
    "\n",
    "    # Link to the work\n",
    "    work_link = links.get(\"paths__works\", {}).get(\"where\", \"\")\n",
    "    work_id = extract_cmcl_number(work_link)\n",
    "    if work_id:\n",
    "        work_uri = PATHS[f\"works/{work_id}\"]\n",
    "        g.add((title_uri, DCTERMS.references, work_uri))\n",
    "        g.add((work_uri, DCTERMS.isReferencedBy, title_uri))\n",
    "\n",
    "# Output\n",
    "g.serialize(\"../turtles/titles.ttl\", format=\"turtle\")\n",
    "print(\"✅ Saved RDF data to ../turtles/titles.ttl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375d56d5",
   "metadata": {},
   "source": [
    "## Colophons\n",
    "\n",
    "We want output like this:\n",
    "\n",
    "```\n",
    "<http://paths.uniroma1.it/atlas/colophons/105> a coptic:Colophon ;\n",
    "    ns1:translation \"] because (he is) the one which took care of this book at his own expenses, he gave it to the place (τόπος) of Apa E[pima of the acaci]a for the release of his soul (ψυχή) so that might the God of the two great archangels (ἀρχάγγελος) Michael and Gabriel and the Christ[-loving] saint [Epima] protect all his business for blessing him in this world (κόσμος) with everything which belongs to him, [might give] him plenty of peaceful (εἰρηνικός) years [---] him safe from all the snares of the devil (διάβολος) and, then, when he will go out of his body (σῶμα) and he will inherit (κληρονομεῖν) the things of sky, so that might the saint apa E[---] entreat (παρακαλεῖν) the Lord on his behalf so that he could be worthy of hearing the voice full of every joy saying come to me, the blessed of my father, inherit the kingdom which was prepared for you from the foundation (καταβολή) of the world, amen, (so) be it [---].    \"@en ;\n",
    "    dcterms:description \"[± 17]ⲛ̣|[±16]ⲡⲁ|[± 11 ϫⲉⲛⲧⲟ]ϥ | [ⲡⲉⲛⲧⲁϥϥⲓⲡⲣⲟⲟⲩϣ ⲙ]ⲡⲓ|(5)[ϫⲱⲱⲙⲉ ϩⲛⲛⲉϥϩ]ⲓⲥⲉ | [ⲙⲙⲓⲛ ⲙⲙⲟϥ ⲁϥⲧⲁ]ⲁϥ | [ⲉϩⲟⲩⲛ ⲉⲡⲧⲟⲡⲟⲥ ⲛ]ⲁ̣ⲡⲁ ⲉ|[ⲡⲓⲙⲁ ⲙ̄ⲡϣⲁⲛⲧ]ⲉ̣ ϩⲁⲡⲟⲩ|[ϫⲁⲓ ⲛⲧⲉϥⲯⲩⲭ]ⲏ̣ ϫⲉⲕⲁⲥ | (10) [ⲉⲣⲉⲡⲛⲟⲩⲧⲉ ⲙⲛⲡ]ⲛ̣ⲟϭⲥⲛⲁⲩ | [ⲛⲁⲣⲭⲁⲅⲅⲉⲗⲟⲥ] ⲙⲓⲭⲁⲏⲗ | [ⲙⲛⲅⲁⲃⲣⲓⲏⲗ] ⲙ̣ⲛⲡϩⲁ̣ⲅ̣ⲓⲟⲥ | [ⲉⲡⲓⲙⲁ ⲙⲙⲁⲓ]ⲡⲉⲭ(ⲣⲓⲥⲧⲟ)ⲥ̣ ⲣ̣ⲟ̣ⲉ̣|[ⲓⲥ ⲉⲛⲉϥⲭⲣⲓⲁ] ⲧⲏⲣⲟⲩ ⲉ̣ⲩ|(15)[ⲥⲙⲟⲩ ⲉⲣⲟϥ] ϩⲙⲡⲓⲕⲟⲥⲙⲟⲥ | [ⲙⲛⲛⲕⲁ ⲛⲓⲙ ⲉ]ⲧ̣ϣⲟⲟⲡ ⲛⲁϥ | [± 5]ⲏ̣[  ̣] ⲛⲁ̣ϥ̣ ⲛⲟⲩ̣|[ⲙⲏⲏϣⲉ ⲛⲣⲟ]ⲙⲡⲉ ⲛⲓⲣⲏⲛⲓ|[ⲕⲟⲛ ± 6 ⲧ]ⲟ̣ⲩϫⲏⲩ ⲉ̣ⲙ|(20)[ⲙⲟϥ ⲛⲛϭⲟⲣϭⲥ ⲧⲏ]ⲣⲟⲩ ⲙ̣ⲓ̣ⲡⲓ|[ⲇⲓⲁⲃⲟⲗⲟⲥ ⲁⲩⲱ] ⲟⲛ ⲉϥϣⲁⲛ|[ⲉⲓ ⲉⲃⲟⲗ ϩⲛⲥⲱ]ⲙ̣ⲁ̣ ⲛϥϫⲓ|[ⲕⲗⲏⲣⲟⲛⲟⲙⲓⲁ ⲛ]ⲛ̣ⲁ̣ⲧⲡⲉ | [ϫⲉⲕⲁⲥ ⲉⲣⲉⲡϩ]ⲁ̣ⲅⲓⲟⲥ ⲁⲡⲁ ⲉ|(25)[± 4 ⲛⲁⲡⲁⲣⲁ]ⲕ̣ⲁⲗⲓ ⲙⲡϭ(ⲟⲓ)ⲥ | [ⲉϩⲣⲁⲓ ⲉϫⲱϥ ⲛϥⲙ]ⲡ̣ϣⲁ ⲛ̇ⲥⲱⲧⲙ | [ⲉⲧⲉⲥⲙⲏ ⲉⲧⲙ]ⲉϩ ⲛ̇ⲣⲁϣⲉ̣ | [ⲛⲓⲙ ϫⲉⲁⲙⲏ]ⲓⲧⲛ̇ ϣⲁⲣⲟⲓ̈ | [ⲛⲉⲧⲥⲙⲁⲙⲁⲁⲧ] ⲛⲧ[ⲉ]ⲡⲁ|(30)[ⲉⲓⲱⲧ ⲛⲧⲉⲧⲛ]ⲕⲗⲏⲣⲟ|[ⲛⲟⲙⲉⲓ ⲛⲧⲙⲛⲧⲉ]ⲣ̣ⲟ̇ ⲛ̇ⲧⲁⲩ|[ⲥⲃⲧⲱⲧⲥ ⲛⲏⲧ]ⲛ ⲛϫⲓⲛ|[ⲧⲕⲁⲧⲁⲃⲟⲗⲏ ⲙ]ⲡⲕⲟⲥⲙⲟⲥ | ϩⲁⲙⲏⲛ ⲉⲥⲉϣⲱ]ⲡⲉ | (35) [± 10]ⲡ̣ⲟ̣ⲡⲟⲥ | [± 12]ⲅⲁ | [± 11]ⲉ\"@cop,\n",
    "        \"Only the left part of the text remains, due to the bad stato of preservation of the parchment sheet. The two sections are separated by bands made of dots and dashes.\"@en ;\n",
    "    dcterms:identifier \"105\" ;\n",
    "    dcterms:isPartOf <http://paths.uniroma1.it/atlas/manuscripts/209> ;\n",
    "    dcterms:references <http://paths.uniroma1.it/atlas/persons/419> ;\n",
    "    dcterms:type \"colophon\" ;\n",
    "    time:hasBeginning \"801\" ;\n",
    "    time:hasEnd \"925\" .\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7f168ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved RDF data to ../turtles/colophons.ttl\n"
     ]
    }
   ],
   "source": [
    "# Replace this with your actual sample records (truncated here for brevity)\n",
    "with open(\"../data/colophons.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    colophons_data = json.load(f)\n",
    "\n",
    "# Namespaces\n",
    "PATHS = Namespace(\"http://paths.uniroma1.it/atlas/\")\n",
    "SCHEMA = Namespace(\"http://schema.org/\")\n",
    "TIME = Namespace(\"http://www.w3.org/2006/time#\")\n",
    "COPTIC = Namespace(\"http://www.semanticweb.org/sjhuskey/ontologies/2025/7/coptic-metadata-viewer/\")\n",
    "\n",
    "# Create graph\n",
    "g = Graph()\n",
    "g.bind(\"dcterms\", DCTERMS)\n",
    "g.bind(\"paths\", PATHS)\n",
    "g.bind(\"schema\", SCHEMA)\n",
    "g.bind(\"time\", TIME)\n",
    "g.bind(\"coptic\", COPTIC)\n",
    "\n",
    "# Helper to extract manuscript ID from 'where'\n",
    "def extract_id(where_clause):\n",
    "    match = re.search(r\"id\\|=\\|(\\d+)\", where_clause)\n",
    "    return match.group(1) if match else None\n",
    "\n",
    "def extract_cmcl_number(where_clause):\n",
    "    match = re.search(r'cc0*(\\d+)', where_clause)\n",
    "    return match.group(1) if match else None\n",
    "\n",
    "for record in colophons_data:\n",
    "    core = record.get(\"core\", {})\n",
    "    links = record.get(\"links\", {})\n",
    "    plugins = record.get(\"plugins\", {})\n",
    "    # Normalize links into a dict (even if it's wrapped in a list)\n",
    "    raw_manual_links = record.get(\"manualLinks\", {})\n",
    "    if isinstance(raw_manual_links, list):\n",
    "        # Look for the first dict in the list\n",
    "        manual_links = next((item for item in raw_manual_links if isinstance(item, dict)), {})\n",
    "    else:\n",
    "        manual_links = raw_manual_links\n",
    "\n",
    "    colophon_id = core.get(\"id\", {}).get(\"val\")\n",
    "    if not colophon_id:\n",
    "        continue\n",
    "\n",
    "    colophon_uri = PATHS[f\"colophons/{colophon_id}\"]\n",
    "    g.add((colophon_uri, RDF.type, COPTIC.Colophon))\n",
    "    g.add((colophon_uri, DCTERMS.identifier, Literal(colophon_id)))\n",
    "    # Chrono range → temporal (both as separate strings)\n",
    "    g.add((colophon_uri, DCTERMS.type, Literal(\"colophon\")))\n",
    "    if (chronofrom := core.get(\"chronofrom\", {}).get(\"val\")):\n",
    "        g.add((colophon_uri, TIME.hasBeginning, Literal(chronofrom)))\n",
    "    if (chronoto := core.get(\"chronoto\", {}).get(\"val\")):\n",
    "        g.add((colophon_uri, TIME.hasEnd, Literal(chronoto)))\n",
    "    if (istitutionplace := core.get(\"institutionplace\", {}).get(\"val\")):\n",
    "        inst_uri = PATHS[f\"places/{istitutionplace.lower().replace(' ', '-')}\"]\n",
    "        g.add((colophon_uri, DCTERMS.spatial, inst_uri))\n",
    "        g.add((inst_uri, RDF.type, DCMITYPE.Place))\n",
    "        g.add((inst_uri, RDFS.label, Literal(core.get(\"institutionplace\", {}).get(\"val_label\"))))\n",
    "    if (description := core.get(\"description\", {}).get(\"val\")):\n",
    "        g.add((colophon_uri, DCTERMS.description, Literal(description, lang=\"en\")))\n",
    "    if (text := core.get(\"text\", {}).get(\"val\")):\n",
    "        g.add((colophon_uri, DCTERMS.description, Literal(text, lang=\"cop\")))\n",
    "    if (translation := core.get(\"translation\", {}).get(\"val\")):\n",
    "        g.add((colophon_uri, LEXINFO.translation, Literal(translation, lang=\"en\")))\n",
    "\n",
    "    # Link to the manuscript\n",
    "    msid = extract_id(links.get(\"paths__manuscripts\", {}).get(\"where\", \"\"))\n",
    "    if msid:\n",
    "        ms_uri = PATHS[f\"manuscripts/{msid}\"]\n",
    "        g.add((ms_uri, DCTERMS.hasPart, colophon_uri))\n",
    "        g.add((colophon_uri, DCTERMS.isPartOf, ms_uri))\n",
    "\n",
    "    # Link to the persons\n",
    "    for mlink in manual_links.values():\n",
    "        if mlink.get(\"tb_stripped\") == \"persons\":\n",
    "            person_id = mlink.get(\"ref_id\")\n",
    "            if person_id:\n",
    "                person_uri = PATHS[f\"persons/{person_id}\"]\n",
    "                g.add((colophon_uri, DCTERMS.references, person_uri))\n",
    "\n",
    "# Output\n",
    "g.serialize(\"../turtles/colophons.ttl\", format=\"turtle\")\n",
    "print(\"✅ Saved RDF data to ../turtles/colophons.ttl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3b07f7",
   "metadata": {},
   "source": [
    "## Places\n",
    "\n",
    "We want output like this:\n",
    "\n",
    "```\n",
    "<http://paths.uniroma1.it/atlas/places/345> a lawd:Place ;\n",
    "    rdfs:label \"Talit\"@en ;\n",
    "    lawd:primaryForm \"Talit\"@en ;\n",
    "    skos:exactMatch <http://pleiades.stoa.org/places/737065>,\n",
    "        <https://www.trismegistos.org/place/2236> .\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "928b5548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Wrote '../turtles/places.ttl'\n"
     ]
    }
   ],
   "source": [
    "# Load your plain JSON\n",
    "with open(\"../data/places.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Setup RDF graph and namespaces\n",
    "g = Graph()\n",
    "LAWD = Namespace(\"http://lawd.info/ontology/\")\n",
    "g.bind(\"lawd\", LAWD)\n",
    "g.bind(\"skos\", SKOS)\n",
    "g.bind(\"rdfs\", RDFS)\n",
    "\n",
    "# Loop through top-level entries (skip _:genid ones)\n",
    "for uri, properties in data.items():\n",
    "    if not uri.startswith(\"http://paths.uniroma1.it/atlas/places/\"):\n",
    "        continue  # Skip _:genid blocks\n",
    "\n",
    "    subj = URIRef(uri)\n",
    "\n",
    "    # Add type triple if present\n",
    "    types = properties.get(\"http://www.w3.org/1999/02/22-rdf-syntax-ns#type\", [])\n",
    "    for t in types:\n",
    "        g.add((subj, RDF.type, URIRef(t[\"value\"])))\n",
    "\n",
    "    # Add exactMatch links\n",
    "    matches = properties.get(\"http://www.w3.org/2004/02/skos/core#exactMatch\", [])\n",
    "    for m in matches:\n",
    "        g.add((subj, SKOS.exactMatch, URIRef(m[\"value\"])))\n",
    "\n",
    "    # Add rdfs:label\n",
    "    labels = properties.get(\"http://www.w3.org/2000/01/rdf-schema#label\", [])\n",
    "    for l in labels:\n",
    "        lang = l.get(\"lang\")\n",
    "        g.add((subj, RDFS.label, Literal(l[\"value\"], lang=lang)))\n",
    "\n",
    "    # Add lawd:primaryForm\n",
    "    primary_forms = properties.get(\"http://lawd.info/ontology/primaryForm\", [])\n",
    "    for pf in primary_forms:\n",
    "        lang = pf.get(\"lang\")\n",
    "        g.add((subj, LAWD.primaryForm, Literal(pf[\"value\"], lang=lang)))\n",
    "\n",
    "# Output the filtered Turtle\n",
    "g.serialize(\"../turtles/places.ttl\", format=\"turtle\")\n",
    "print(\"✅ Wrote '../turtles/places.ttl'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a3b9d1",
   "metadata": {},
   "source": [
    "## Validate TTL Files\n",
    "\n",
    "Make sure that all the turtles are valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50dff41e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating ../turtles/persons.ttl...\n",
      "Validating ../turtles/works.ttl...\n",
      "Validating ../turtles/manuscripts.ttl...\n",
      "Validating ../turtles/colophons.ttl...\n",
      "Validating ../turtles/collections.ttl...\n",
      "Validating ../turtles/statements.ttl...\n",
      "Validating ../turtles/authors.ttl...\n",
      "Validating ../turtles/places.ttl...\n",
      "Validating ../turtles/titles.ttl...\n",
      "TTL is valid!\n"
     ]
    }
   ],
   "source": [
    "g = Graph()\n",
    "# Loop over all Turtle files in the directory\n",
    "for ttl_file in glob.glob(\"../turtles/*.ttl\"):\n",
    "    if not os.path.isfile(ttl_file):\n",
    "        continue  # Skip if it's not a file\n",
    "    print(f\"Validating {ttl_file}...\")\n",
    "    g.parse(ttl_file, format=\"turtle\")\n",
    "print(\"TTL is valid!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4362aa",
   "metadata": {},
   "source": [
    "## Merge the Turtle files into one graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "022097a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged: persons.ttl\n",
      "Merged: works.ttl\n",
      "Merged: manuscripts.ttl\n",
      "Merged: colophons.ttl\n",
      "Merged: collections.ttl\n",
      "Merged: statements.ttl\n",
      "Merged: authors.ttl\n",
      "Merged: places.ttl\n",
      "Merged: titles.ttl\n",
      "Total triples in original graphs: 470639\n",
      "Total triples in merged graph: 188288\n",
      "Merged Turtle graph is valid!\n",
      "✅ Merged Turtle graph is valid and saved to ../turtles/graph.ttl\n"
     ]
    }
   ],
   "source": [
    "# Directory containing your Turtle files\n",
    "input_dir = \"../turtles\"\n",
    "output_file = \"../turtles/graph.ttl\"\n",
    "\n",
    "# Create an empty graph\n",
    "merged_graph = Graph()\n",
    "\n",
    "# Iterate through Turtle files and parse each one\n",
    "for filename in os.listdir(input_dir):\n",
    "    if filename.endswith(\".ttl\"):\n",
    "        path = os.path.join(input_dir, filename)\n",
    "        merged_graph.parse(path, format=\"turtle\")\n",
    "        print(f\"Merged: {filename}\")\n",
    "\n",
    "# Serialize the merged graph (duplicates are already removed)\n",
    "merged_graph.serialize(destination=output_file, format=\"turtle\")\n",
    "print(f\"Total triples in original graphs: {sum(len(Graph().parse(os.path.join(input_dir, f), format='turtle')) for f in os.listdir(input_dir) if f.endswith('.ttl'))}\")\n",
    "print(f\"Total triples in merged graph: {len(merged_graph)}\")\n",
    "\n",
    "# Validate the merged graph\n",
    "g = Graph()\n",
    "g.parse(output_file, format=\"turtle\")\n",
    "print(\"Merged Turtle graph is valid!\")\n",
    "print(f\"✅ Merged Turtle graph is valid and saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fd854e",
   "metadata": {},
   "source": [
    "## Add inferences\n",
    "\n",
    "This block mimics the action of a reasoner. It looks for triples that reference other triples and adds them explicitly to existing turtles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "315c84ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=N594dba656a26407db4c41202ebf99922 (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rdflib import Graph, Namespace, URIRef\n",
    "\n",
    "# Load your graph\n",
    "g = Graph()\n",
    "g.parse(\"../turtles/graph.ttl\", format=\"ttl\")  # Adjust if needed\n",
    "\n",
    "# Define the namespaces\n",
    "DCTERMS = Namespace(\"http://purl.org/dc/terms/\")\n",
    "\n",
    "# Apply the inference rule\n",
    "inferred_triples = set()\n",
    "for title, _, work in g.triples((None, DCTERMS.references, None)):\n",
    "    for _, _, author in g.triples((work, DCTERMS.creator, None)):\n",
    "        triple = (title, DCTERMS.creator, author)\n",
    "        if triple not in g:\n",
    "            inferred_triples.add(triple)\n",
    "\n",
    "for title, _, work in g.triples((None, DCTERMS.references, None)):\n",
    "    triple = (work, DCTERMS.isReferencedBy, title)\n",
    "    if triple not in g:\n",
    "        inferred_triples.add(triple)\n",
    "\n",
    "# Add inferred triples to the graph\n",
    "for triple in inferred_triples:\n",
    "    g.add(triple)\n",
    "\n",
    "# Save the updated graph (optional)\n",
    "g.serialize(\"../turtles/graph_with_inference.ttl\", format=\"turtle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77188e26",
   "metadata": {},
   "source": [
    "## Get the overall schema for the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4189a395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "coptic:Author:\n",
      "  dcterms:creator\n",
      "  dcterms:description\n",
      "  dcterms:identifier\n",
      "  foaf:name\n",
      "  owl:sameAs\n",
      "  rdf:type\n",
      "  schema1:title\n",
      "\n",
      "coptic:Colophon:\n",
      "  dcterms:description\n",
      "  dcterms:identifier\n",
      "  dcterms:isPartOf\n",
      "  dcterms:references\n",
      "  dcterms:type\n",
      "  ns1:translation\n",
      "  rdf:type\n",
      "  time:hasBeginning\n",
      "  time:hasEnd\n",
      "\n",
      "coptic:Manuscript:\n",
      "  dcterms:bibliographicCitation\n",
      "  dcterms:description\n",
      "  dcterms:hasPart\n",
      "  dcterms:identifier\n",
      "  dcterms:isPartOf\n",
      "  dcterms:medium\n",
      "  rdf:type\n",
      "  time:hasBeginning\n",
      "  time:hasEnd\n",
      "\n",
      "coptic:Title:\n",
      "  dcterms:creator\n",
      "  dcterms:description\n",
      "  dcterms:identifier\n",
      "  dcterms:isPartOf\n",
      "  dcterms:references\n",
      "  dcterms:type\n",
      "  rdf:type\n",
      "\n",
      "dcmitype:Collection:\n",
      "  dcterms:hasPart\n",
      "  dcterms:identifier\n",
      "  dcterms:spatial\n",
      "  rdf:type\n",
      "  schema1:location\n",
      "  schema1:name\n",
      "\n",
      "foaf:Person:\n",
      "  dcterms:identifier\n",
      "  dcterms:isReferencedBy\n",
      "  foaf:name\n",
      "  ns1:transliteration\n",
      "  rdf:type\n",
      "  rdfs:label\n",
      "  schema1:birthPlace\n",
      "  schema1:gender\n",
      "  schema1:roleName\n",
      "  time:hasBeginning\n",
      "  time:hasEnd\n",
      "\n",
      "frbr:Work:\n",
      "  dcterms:creator\n",
      "  dcterms:description\n",
      "  dcterms:identifier\n",
      "  dcterms:isPartOf\n",
      "  dcterms:isReferencedBy\n",
      "  dcterms:temporal\n",
      "  dcterms:title\n",
      "  rdf:type\n",
      "  rdfs:label\n",
      "\n",
      "lawd:Place:\n",
      "  lawd:primaryForm\n",
      "  rdf:type\n",
      "  rdfs:label\n",
      "  skos:exactMatch\n",
      "\n",
      "owl:Class:\n",
      "  owl:equivalentClass\n",
      "  rdf:type\n",
      "  rdfs:comment\n",
      "  rdfs:label\n",
      "  rdfs:subClassOf\n",
      "\n",
      "owl:DatatypeProperty:\n",
      "  rdf:type\n",
      "  rdfs:comment\n",
      "  rdfs:range\n",
      "\n",
      "owl:ObjectProperty:\n",
      "  owl:inverseOf\n",
      "  rdf:type\n",
      "  rdfs:comment\n",
      "  rdfs:domain\n",
      "  rdfs:range\n",
      "\n",
      "owl:Ontology:\n",
      "  rdf:type\n",
      "  rdfs:comment\n",
      "\n",
      "owl:Restriction:\n",
      "  owl:hasValue\n",
      "  owl:onProperty\n",
      "  owl:someValuesFrom\n",
      "  rdf:type\n",
      "\n",
      "owl:TransitiveProperty:\n",
      "  owl:inverseOf\n",
      "  rdf:type\n",
      "  rdfs:comment\n",
      "  rdfs:domain\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from rdflib import Graph\n",
    "\n",
    "# Load the merged graph\n",
    "g = Graph()\n",
    "g.parse(\"../turtles/graph_with_inference.ttl\", format=\"turtle\")\n",
    "\n",
    "# Dictionary to store classes and their properties\n",
    "class_properties = defaultdict(set)\n",
    "\n",
    "# Get all triples and organize by class\n",
    "for subject, predicate, obj in g:\n",
    "    # Get the types (classes) of the subject\n",
    "    for s, p, class_uri in g.triples((subject, RDF.type, None)):\n",
    "        if s == subject:  # Make sure we're looking at the right subject\n",
    "            # Convert URIs to prefixed format\n",
    "            try:\n",
    "                class_name = g.namespace_manager.qname(class_uri)\n",
    "            except:\n",
    "                class_name = str(class_uri)\n",
    "            \n",
    "            try:\n",
    "                property_name = g.namespace_manager.qname(predicate)\n",
    "            except:\n",
    "                property_name = str(predicate)\n",
    "            \n",
    "            class_properties[class_name].add(property_name)\n",
    "\n",
    "# Sort and display results\n",
    "for class_name in sorted(class_properties.keys()):\n",
    "    print(f\"\\n{class_name}:\")\n",
    "    for prop in sorted(class_properties[class_name]):\n",
    "        print(f\"  {prop}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8889c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "schroeder",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
